{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DUN4hUuyFnB"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "## **FACE MASK DETECTION USING YOLOv8**\n",
        "---\n",
        "**OVERVIEW:**\n",
        "\n",
        "This notebook implements a complete computer vision pipeline for detecting face masks\n",
        "in images using the YOLOv8 object detection model. The system can identify three\n",
        "different mask-wearing scenarios with high accuracy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHjF6Dj1zDYQ"
      },
      "source": [
        "## **SECTION 1: Setup Kaggle API and Download Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gORUfxpZy9Z9",
        "outputId": "54485755-f8a0-484d-f0ce-b18f64490feb"
      },
      "outputs": [],
      "source": [
        "# Create kaggle directory and setup API credentials\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUDpyL16z1dM",
        "outputId": "0c98d6d3-b86f-47de-af03-5f82b691983a"
      },
      "outputs": [],
      "source": [
        "# Download the face mask detection dataset from Kaggle\n",
        "#!/bin/bash\n",
        "!kaggle datasets download andrewmvd/face-mask-detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGazGB5jz6MS",
        "outputId": "adec336d-133f-446e-cb54-7672e9e2552a"
      },
      "outputs": [],
      "source": [
        "# Extract the downloaded dataset\n",
        "!unzip face-mask-detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JHgYWjL0EsR"
      },
      "source": [
        "## **SECTION 2: Data Preprocessing - XML to YOLO Format Conversion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uSGqfAAn0BVr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aozq-cFN0MYZ"
      },
      "outputs": [],
      "source": [
        "# Define directory paths\n",
        "annotations_path = '/content/annotations'  # XML annotation files\n",
        "labels_dir       = '/content/Labels'       # Output directory for YOLO format labels\n",
        "images_dir       = '/content/images'       # Original images directory\n",
        "base_dir         = 'dataset'               # Base directory for organized dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PsxanTJM0R8k"
      },
      "outputs": [],
      "source": [
        "# Create directory structure for train/validation split\n",
        "img_train_dir    = os.path.join(base_dir, 'images/train')\n",
        "img_val_dir      = os.path.join(base_dir, 'images/val')\n",
        "lbl_train_dir    = os.path.join(base_dir, 'labels/train')\n",
        "lbl_val_dir      = os.path.join(base_dir, 'labels/val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "j2L9xfyv0Vet"
      },
      "outputs": [],
      "source": [
        "# Create all necessary directories\n",
        "os.makedirs(labels_dir, exist_ok=True)\n",
        "for d in [img_train_dir, img_val_dir, lbl_train_dir, lbl_val_dir]:\n",
        "    os.makedirs(d, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HUiVhFQt0aZE"
      },
      "outputs": [],
      "source": [
        "# Define class mapping for YOLO format (class names to numeric IDs)\n",
        "label_map = {\n",
        "    \"with_mask\": 0,                # Person wearing mask correctly\n",
        "    \"without_mask\": 1,             # Person not wearing mask\n",
        "    \"mask_weared_incorrect\": 2     # Person wearing mask incorrectly\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saO-DZa10evB",
        "outputId": "251f1752-2411-44eb-818d-8b5077ffdf29"
      },
      "outputs": [],
      "source": [
        "# Convert XML annotations to YOLO format\n",
        "print(\"Converting XML annotations to YOLO format...\")\n",
        "for xml_file in os.listdir(annotations_path):\n",
        "    if not xml_file.endswith('.xml'):\n",
        "        continue\n",
        "\n",
        "    # Parse XML file\n",
        "    tree = ET.parse(os.path.join(annotations_path, xml_file))\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Get image dimensions\n",
        "    img_w = int(root.find('size/width').text)\n",
        "    img_h = int(root.find('size/height').text)\n",
        "\n",
        "    yolo_lines = []\n",
        "\n",
        "    # Process each object (bounding box) in the image\n",
        "    for obj in root.findall('object'):\n",
        "        class_name = obj.find('name').text.lower()\n",
        "\n",
        "        # Skip if class not in our label map\n",
        "        if class_name not in label_map:\n",
        "            continue\n",
        "\n",
        "        class_id = label_map[class_name]\n",
        "\n",
        "        # Get bounding box coordinates\n",
        "        bbox = obj.find('bndbox')\n",
        "        xmin = int(bbox.find('xmin').text)\n",
        "        ymin = int(bbox.find('ymin').text)\n",
        "        xmax = int(bbox.find('xmax').text)\n",
        "        ymax = int(bbox.find('ymax').text)\n",
        "\n",
        "        # Convert to YOLO format (normalized center coordinates and dimensions)\n",
        "        x_center = ((xmin + xmax) / 2) / img_w\n",
        "        y_center = ((ymin + ymax) / 2) / img_h\n",
        "        width = (xmax - xmin) / img_w\n",
        "        height = (ymax - ymin) / img_h\n",
        "\n",
        "        # Create YOLO format line: class_id x_center y_center width height\n",
        "        line = f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
        "        yolo_lines.append(line)\n",
        "\n",
        "    # Save YOLO format annotation file\n",
        "    out_filename = os.path.splitext(xml_file)[0] + '.txt'\n",
        "    with open(os.path.join(labels_dir, out_filename), 'w') as f:\n",
        "        f.write('\\n'.join(yolo_lines))\n",
        "\n",
        "print(\"Done converting XML to YOLO format!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIBzaqzl0p7Z"
      },
      "source": [
        "## **SECTION 3: Dataset Split - Train/Validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rDHB_LUj0mU7"
      },
      "outputs": [],
      "source": [
        "# Get all image files\n",
        "image_files = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png'))]\n",
        "random.shuffle(image_files)  # Randomize order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AJPzttPD0zID"
      },
      "outputs": [],
      "source": [
        "# Split dataset: 80% training, 20% validation\n",
        "split_idx = int(0.8 * len(image_files))\n",
        "train_files = image_files[:split_idx]\n",
        "val_files = image_files[split_idx:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HIGlaRSj01b5"
      },
      "outputs": [],
      "source": [
        "def move_split(file_list, target_img_dir, target_lbl_dir):\n",
        "    \"\"\"\n",
        "    Move images and their corresponding labels to target directories\n",
        "\n",
        "    Args:\n",
        "        file_list: List of image filenames to move\n",
        "        target_img_dir: Target directory for images\n",
        "        target_lbl_dir: Target directory for labels\n",
        "    \"\"\"\n",
        "    for img_file in file_list:\n",
        "        img_src = os.path.join(images_dir, img_file)\n",
        "        lbl_src = os.path.join(labels_dir, os.path.splitext(img_file)[0] + '.txt')\n",
        "\n",
        "        # Copy image file\n",
        "        shutil.copy(img_src, os.path.join(target_img_dir, img_file))\n",
        "\n",
        "        # Copy corresponding label file if it exists\n",
        "        if os.path.exists(lbl_src):\n",
        "            shutil.copy(lbl_src, os.path.join(target_lbl_dir, os.path.basename(lbl_src)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI2mGRL309c0",
        "outputId": "2971116f-b451-4859-bbde-e2331158143a"
      },
      "outputs": [],
      "source": [
        "# Move files to train and validation directories\n",
        "move_split(train_files, img_train_dir, lbl_train_dir)\n",
        "move_split(val_files, img_val_dir, lbl_val_dir)\n",
        "\n",
        "print(\"Dataset split completed!\")\n",
        "print(f\"Training images: {len(train_files)}\")\n",
        "print(f\"Validation images: {len(val_files)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shzaBHJR1Gky"
      },
      "source": [
        "## **SECTION 4: Create YAML Configuration File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkBgnms71Dux",
        "outputId": "f212871c-a31f-413a-a52d-c747c7884e99"
      },
      "outputs": [],
      "source": [
        "# Create YAML configuration file for YOLOv8 training\n",
        "yaml_content = \"\"\"\n",
        "path: /content/dataset\n",
        "train: /content/dataset/images/train\n",
        "val: /content/dataset/images/val\n",
        "names:\n",
        "  0: with_mask\n",
        "  1: without_mask\n",
        "  2: mask_weared_incorrect\n",
        "\"\"\"\n",
        "\n",
        "# Save the YAML configuration file\n",
        "with open(\"/content/face_mask.yaml\", \"w\") as f:\n",
        "    f.write(yaml_content.strip())\n",
        "\n",
        "print(\"YAML configuration file created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG89kszu1UQ6"
      },
      "source": [
        "## **SECTION 5: Install YOLOv8 and Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Um45hMka1Rcx",
        "outputId": "88585134-03ec-472f-ee6e-cf053e686388"
      },
      "outputs": [],
      "source": [
        "# Install ultralytics package for YOLOv8\n",
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BN1xiy2L1cwR"
      },
      "outputs": [],
      "source": [
        "# Import YOLO\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGA3ElGe2Cdt",
        "outputId": "42d88958-966d-4269-de26-0568157913b8"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained YOLOv8 nano model (smallest and fastest)\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Train the model\n",
        "model.train(\n",
        "    data='/content/face_mask.yaml',    # Path to dataset configuration\n",
        "    epochs=200,                        # Number of training epochs\n",
        "    imgsz=416,                        # Input image size\n",
        "    batch=16,                         # Batch size\n",
        "    name='mask_detector'              # Name for this training run\n",
        ")\n",
        "\n",
        "print(\"Training completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLI-SFNr8qia"
      },
      "source": [
        "## **SECTION 6: Model Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW97tQX-4K6U",
        "outputId": "305ab1e0-f731-4e9e-f90f-9317137de4d7"
      },
      "outputs": [],
      "source": [
        "# Define path to the best trained model weights\n",
        "yol_path = \"runs/detect/mask_detector5/weights/best.pt\"\n",
        "\n",
        "# Load the trained model and evaluate on validation set\n",
        "model = YOLO(yol_path)\n",
        "print(\"Evaluating model performance...\")\n",
        "metrics = model.val(data='/content/face_mask.yaml')\n",
        "print(\"Validation metrics:\", metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9pL8BhN85sa"
      },
      "source": [
        "## **SECTION 7: Visualize Predictions on Validation Set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4wyfSJkn9BDh"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HYoN63Ox9ETq",
        "outputId": "d3201c7d-4d45-403d-90ec-6a51a2828ba4"
      },
      "outputs": [],
      "source": [
        "# Load the trained model\n",
        "model = YOLO(yol_path)\n",
        "\n",
        "# Get validation images for testing\n",
        "images_dir = '/content/dataset/images/val'\n",
        "all_images = [f for f in os.listdir(images_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "# Select 10 random images for visualization\n",
        "random_images = random.sample(all_images, 10)\n",
        "\n",
        "# Create visualization\n",
        "plt.figure(figsize=(20, 40))\n",
        "print(\"Generating predictions on random validation images...\")\n",
        "\n",
        "for i, img_name in enumerate(random_images):\n",
        "    img_path = os.path.join(images_dir, img_name)\n",
        "\n",
        "    # Run inference on the image\n",
        "    results = model(img_path)\n",
        "\n",
        "    # Get annotated image with bounding boxes\n",
        "    annotated_img = results[0].plot()\n",
        "\n",
        "    # Count detections by class\n",
        "    counts = {\"with_mask\": 0, \"without_mask\": 0}\n",
        "    for box in results[0].boxes:\n",
        "        cls = int(box.cls.cpu().numpy())\n",
        "        label = model.names[cls]\n",
        "        if label == \"with_mask\":\n",
        "            counts[\"with_mask\"] += 1\n",
        "        elif label == \"without_mask\":\n",
        "            counts[\"without_mask\"] += 1\n",
        "\n",
        "    # Display the result\n",
        "    plt.subplot(5, 2, i+1)\n",
        "    plt.imshow(annotated_img)\n",
        "    plt.title(f\"{img_name}\\nWith Mask: {counts['with_mask']} | Without Mask: {counts['without_mask']}\", fontsize=14)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIC7ljU39Ppi"
      },
      "source": [
        "## **SECTION 8: Test on External Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04SUPsDW9S3A",
        "outputId": "e4d5c96d-b030-47a4-9161-4f84d37253d3"
      },
      "outputs": [],
      "source": [
        "# Download additional test dataset\n",
        "!kaggle datasets download omkargurav/face-mask-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQjGnbqz9Yh8",
        "outputId": "6159d150-3bb0-4650-97c4-182d7ba0120d"
      },
      "outputs": [],
      "source": [
        "# Extract the test dataset\n",
        "!unzip face-mask-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o7dh_DDJ3uY",
        "outputId": "3d0cb9cc-52e8-45d0-b926-1034c000f525"
      },
      "outputs": [],
      "source": [
        "# Organize test images into a single folder\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define source folders\n",
        "folder1 = '/content/data/with_mask'      # Images with masks\n",
        "folder2 = '/content/data/without_mask'   # Images without masks\n",
        "final_folder = '/content/Final_test'     # Combined test folder\n",
        "\n",
        "# Create test folder\n",
        "os.makedirs(final_folder, exist_ok=True)\n",
        "\n",
        "# Collect all images from both folders\n",
        "all_images = []\n",
        "for folder in [folder1, folder2]:\n",
        "    images = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "    all_images.extend(images)\n",
        "\n",
        "# Shuffle and copy to final test folder\n",
        "random.shuffle(all_images)\n",
        "for img_path in all_images:\n",
        "    filename = os.path.basename(img_path)\n",
        "    shutil.copy(img_path, os.path.join(final_folder, filename))\n",
        "\n",
        "print(f\"Test dataset prepared with {len(all_images)} images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ_VaqTDKFPi"
      },
      "source": [
        "## **SECTION 9: Run Inference on Test Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9BIootNuJ_ak",
        "outputId": "fda0a677-1b42-4d75-e973-d00f3e1215cb"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Load the trained model\n",
        "model = YOLO(yol_path)\n",
        "\n",
        "# Get all test images\n",
        "folder_path = '/content/Final_test'\n",
        "image_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
        "               if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
        "\n",
        "print(f\"Running inference on {len(image_files)} test images...\")\n",
        "print(\"Displaying results with bounding boxes and confidence scores...\")\n",
        "\n",
        "# Process each test image\n",
        "for img_path in image_files:\n",
        "    # Run inference\n",
        "    results = model(img_path)\n",
        "\n",
        "    # Get annotated image with predictions\n",
        "    annotated_img = results[0].plot()\n",
        "\n",
        "    # Display the result\n",
        "    cv2_imshow(annotated_img)\n",
        "\n",
        "print(\"Inference completed on all test images!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXFP3PQEKUvY"
      },
      "outputs": [],
      "source": [
        "model.save('face_mask_detector.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
